{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Información a compartir \n",
    "---\n",
    "Todo lo útil encontrado dejarlo registrado en este Jupyter.\n",
    "\n",
    "[conceptos](#conceptos), [trabajos](#trabajos) y [data](#data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"conceptos\"></a>\n",
    "### Conceptos\n",
    "---\n",
    "* Estrella variable: ..\n",
    "\n",
    "* LombScargle: Least-squares frequency analysis of unequally spaced data. Encuentra el periodo que minimiza el error de un modelo sinosoidal sobre la curva\n",
    "\n",
    "* Mandel-Agol: trabajo del año 2002 (https://arxiv.org/abs/astro-ph/0210099) donde presenta una función para modelar una curva de luz de una manera bastante smooth y simple (cuando el planeta no eclispa a la estrella la intensidad es máxima, cero, cuando el planeta eclipsa a la estrella es máxima en valor negativo, cuando el planeta está cercano al eclipse se modela con un polinomio cuadrático)\n",
    "\n",
    "* FATS (Feature Analysis Time Series): Librería de python para extraer estadísticos y caract basadas en LombScargle de curva de luz: http://isadoranun.github.io/tsfeat/FeaturesDocumentation.html\n",
    "\n",
    "* TCE (Tresholding Crossing Event): primeros objetos/eventos que sobrepasan un cierto treshold en los datos recolectados por Kepler, los cuales se analizan en busca de objetos candidatos vs falsos positivos\n",
    "\n",
    "* Julian Date: Unidad de tiempo del conteo de días desde el 1ero de Enero de 4713 BC\n",
    "* Barycentric Julian Date (BJD): Corrige las diferencias dadas por la posición de la tierra respecto al barycentro del sistema solar (debido a que la velocidad de la luz es finita, la medición puede tener diferencias). Fórmula?? (máxima corrección puede ser de +- 8.4 mins)\n",
    "* Kepler Barycentric Julian Date (KBJD): BJD escalado, para que el cero signifique cuando Kepler empezó a funcionar en 2009.  KBJD = BJD -2454833.\n",
    "* Heliocentric Julain Date (HJD): similar a BJD, corrige diferencias dada por la posición de la tierra respecto al sol (por lo general se usa BJD).\n",
    "    * La diferencia entre HJD y BJD es de hasta ± 4 s.\n",
    "* Phase Fold: en algunos trabajos del estado del arte se señala este término y hace referencia a “centrar” la curva de luz en el tránsito con una ventana del tamaño proporcional al periodo, denominado como fase de la curva (tránsito)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"trabajos\"></a>\n",
    "## Trabajos de curvas de luz\n",
    "---\n",
    "\n",
    "#### Estrellas Variables\n",
    "> **Richards et al. (2011)**\n",
    "* *On machine-learned classification of variable stars with sparse and noisy time-series data* \n",
    "* Idea: Analiza estrellas variables, extrae características manuales de las curvas de luz (estadísticos simples y otras características del periodo y análisis LombScargle)\n",
    "* Modelo: Variaciones de árboles de decisión (normal, boost, RF, CART, etc) y SVM.\n",
    "\n",
    "> **Donalek et al. (2013)**\n",
    "* *Feature selection strategies for classifying high dimensional astronomical data sets*\n",
    "* Idea: Analiza estrellas variables, datos trabajos sobre Catalina Real-Time Transient Survey (CRTS) y la misión Kepler, extrae características similares a Richards et al.\n",
    "* Modelo: k-NN y Árboles de decisión\n",
    "\n",
    "\n",
    "> **Mahabal et al. (2017)**\n",
    "* *Deep-learnt classification of light curves*\n",
    "* Idea: Analiza estrellas variables, datos trabajos sobre CRTS, transforma la representación de la curva de luz a una imagen (grilla) a través de las variaciones/delta de las magnitudes/mediciones y de los intervalos de tiempo.\n",
    "* Modelo: Convolutional  neural network\n",
    "\n",
    "> **C Aguirre et al. (2017)**\n",
    "* *Deep multi-survey classification of variable stars*\n",
    "* Idea: Clasifica estrellas variables a través de procesar las curvas de luz con redes convolucionales 1D agregando el tiempo como entrada extra. Utiliza técnicas de data augmentation interesantes.\n",
    "* Utiliza representación con tiempo añadido como dato\n",
    "* Modelo: Convolutional  neural network\n",
    "\n",
    "> **B Naut et al. (2018)**\n",
    "* *A recurrent neural network for classification of unevenly sampled variable stars*\n",
    "* Idea: Utilizar un autoencoder recurrente para codificar la información de las estrellas variables, particiona curva de luz en subsequencias de largo pequeño (200). Valida con la misma función de pérdida de reconstrucción y con utilizar la representación latente para clasificar los tipos de estrellas variables. Utiliza diferentes dataset y entrena sobre cada uno antes.\n",
    "* Utiliza representación con tiempo añadido como dato, además de **phase folded**\n",
    "* Modelo: Recurrent neural network\n",
    "\n",
    "> **Tsang et al. (2019)**\n",
    "* *Deep Neural Network Classifier for Variable Stars with Novelty Detection Capability*\n",
    "* IDea: : Extiende casi todo lo realizado por Naut, asume el ground truth de sus datasets como el de RF (los que tengan harta credibilidad) similar a Shallue. Utiliza la representación codificada por el modelo para aprender simultaneamente la clasificación sobre estrellas variables, entrena en dos fases.\n",
    "* Utiliza representación con tiempo añadido como dato, además de **phase folded**\n",
    "* Modelo: Recurrent neural network\n",
    "\n",
    "\n",
    "#### Tránsitos (exoplanetas)\n",
    "> **McCauliff et al. (2015)**\n",
    "* *Automatic Classification of Kepler Planetary Transit Candidate*\n",
    "* Idea: Proyecto Autovetter, sobre dataset TCE (Tresholding Crossing Event) identifica objetos candidatos a ser transientes (tres clases: planet candidates, AFPs (astrophysical false positives), and NTP (not transit planet), también experimenta con 2 tipos, falsos positivos agrupados vs candidatos), utiliza modelo de aprendizaje sobre las características de la pipeline de kepler (metadatos). (acc en 3clases: 97,3, 2clases: 98)\n",
    "* Modelo: Random Forest\n",
    "\n",
    "> **Thompson et al. (2015)**\n",
    "* *A Machine Learning Technique To Identify Transit Shaped Signal*\n",
    "* Idea: sobre dataset TCE, identifica objetos candidatos, similar a proyecto Autovetter, utiliza aprendizaje no supervisado para reducir dimensionalidad de las curvas de luz de Kepler y que clusterice estructuras similares (proyección LPP). \n",
    "* Utiliza representación **phase folded**\n",
    "* Modelo: k-NN\n",
    "\n",
    "> **Armstrong et al. (2017)**  \n",
    "* *Transit shapes and self-organizing maps as a tool for ranking planetary candidates: application to Kepler and K2*  \n",
    "* Idea: sobre dataset KOI de Kepler (2016), identifica objetos con forma de transito (planetas de falsos positivos). Utiliza aprendizaje no supervisado para reducir dimensionalidad de la curvas a 2 dimensiones y luego utilizar un modelo de clasificación parecido a mezcla de gausianas (estilo k-nn sin radios \"redondos\"). Llega a 90 acc approx.\n",
    "* Utiliza representación **phase folded**\n",
    "* Modelo: simi a weightet k-NN\n",
    "\n",
    "> **Hinners et al. (2018)**\n",
    "* *Machine learning techniques for stellar light curve classification*\n",
    "* Idea: Analiza estadísticos de Kepler KOI, utiliza diferentes modelos de aprendizaje para predecir las características de Kepler (metadatos). Extrae estadísticos como Richards et al. de las curvas de luz.\n",
    "* Modelo: varias clasificadores clasicos (SVM, k-NN, Naive Bayes, RF)\n",
    "\n",
    "\n",
    "> **Shallue & Vanderburg (2018)**\n",
    "* *Identifying Exoplanets with Deep Learning A Five-planet Resonant Chain around Kepler-80 and an Eighth Planet around Kepler-9*\n",
    "* Idea: sobre dataset TCE, etiquetas son las generadas por proyecto Autovetter, representa las curvas de luz centradas en el tránsito y ajusta a diferentes escalas en base a un muestreo como fracción en base al periodo o transit duration. Finalmente clasifica con red feed forward y convolucionales, convolucionales obtiene resultados bastante buenos (acc 96, AUC 98,8)\n",
    "* Utiliza representación **phase folded**\n",
    "* Modelo: Convolutional  neural network\n",
    "\n",
    "\n",
    "> **Pearson et al. (2017-2018)**\n",
    "* *Searching for Exoplanets using Artificial Intelligence*\n",
    "* Idea: Entrena sobre data simulada (tránsitos)- modelo creado por él- para identificar tránsitos de no. Experimenta con evaluar sobre datos de Kepler\n",
    "* Utiliza representación **phase folded**\n",
    "* Modelo: Convolutional  neural network\n",
    "\n",
    "\n",
    "> **Schanche et al. (2018)**\n",
    "* *Machine-learning Approaches to Exoplanet Transit Detection and Candidate Validation in Wide-field Ground-based Surveys*\n",
    "* Idea: Detectar candidatos a tránsitos dentro de estrellas binarias y estrellas variables (multi-clases, con 4), utilizando metadatos de **WASP** y además explora con trabajar directamente sobre la curva de luz con una arquitectura convolucional neuronal similar a Shallue.\n",
    "* Utiliza representación **phase folded**.\n",
    "* Modelo: Convolutional  neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"?\"></a>\n",
    "### Trabajos con Convolucionales sobre LC\n",
    "---\n",
    "\n",
    "\n",
    "> **Shallue & Vanderburg (2018)**\n",
    "* *Identifying Exoplanets with Deep Learning A Five-planet Resonant Chain around Kepler-80 and an Eighth Planet around Kepler-9*\n",
    "* Arquitectura profunda convolucional (se ve buena a imitar), codigo contiene pre-procesamiento bueno\n",
    "* code: https://github.com/google-research/exoplanet-ml\n",
    "\n",
    "> **C Aguirre et al. (2017)**\n",
    "* *Deep multi-survey classification of variable stars*\n",
    "* Arquitectura shallow convolucional (tiene buenos fundamentos pero no se ve buena a imitar)\n",
    "* code: https://github.com/C-Aguirre017/DeepMultiSurveyClassificationOfVariableStars\n",
    "\n",
    "> **BTH Zhang et al. (2019)** y **B Naut et al. (2017)**\n",
    "* *Deep Neural Network Classifier for Variable Stars with Novelty Detection Capability* y *A recurrent neural network for classification of unevenly sampled variable stars*\n",
    "* Arquitectura AE con recurrentes, agrega tiempo (esta bastante relacionada la arquitectura)\n",
    "* code: https://github.com/bnaul/IrregularTimeSeriesAutoencoderPaper\n",
    "* code: https://github.com/bthtsang/DeepClassifierNoveltyDetection\n",
    "\n",
    "\n",
    "> **Pearson et al. (2018)**  \n",
    "> * Arquitecutra convolucional de solo 1 capa.  \n",
    "> * code: https://github.com/pearsonkyle/Exoplanet-Artificial-Intelligence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
